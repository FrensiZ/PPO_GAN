pre-training...
epoch:	0	train_loss:	3.69803	val_loss:	3.08606
epoch:	5	train_loss:	2.86681	val_loss:	2.86355
epoch:	10	train_loss:	2.73455	val_loss:	2.74475
epoch:	15	train_loss:	2.67697	val_loss:	2.70382
epoch:	20	train_loss:	2.63965	val_loss:	2.66913
epoch:	25	train_loss:	2.61168	val_loss:	2.64388
epoch:	30	train_loss:	2.58880	val_loss:	2.62453
epoch:	35	train_loss:	2.56891	val_loss:	2.60979
epoch:	40	train_loss:	2.55490	val_loss:	2.59478
epoch:	45	train_loss:	2.54246	val_loss:	2.58074
epoch:	50	train_loss:	2.52706	val_loss:	2.57033
epoch:	55	train_loss:	2.51519	val_loss:	2.55925
epoch:	60	train_loss:	2.50568	val_loss:	2.54914
epoch:	65	train_loss:	2.49459	val_loss:	2.54089
epoch:	70	train_loss:	2.48335	val_loss:	2.53634
epoch:	75	train_loss:	2.47748	val_loss:	2.53225
epoch:	80	train_loss:	2.46729	val_loss:	2.52714
epoch:	85	train_loss:	2.45996	val_loss:	2.52771
epoch:	90	train_loss:	2.45254	val_loss:	2.51722
epoch:	95	train_loss:	2.44595	val_loss:	2.51599
epoch:	100	train_loss:	2.43983	val_loss:	2.51191
epoch:	105	train_loss:	2.43396	val_loss:	2.51217
epoch:	110	train_loss:	2.42545	val_loss:	2.51308
epoch:	115	train_loss:	2.41809	val_loss:	2.50796
epoch:	120	train_loss:	2.41282	val_loss:	2.50730
epoch:	125	train_loss:	2.41165	val_loss:	2.50779
epoch:	130	train_loss:	2.40944	val_loss:	2.50743
epoch:	135	train_loss:	2.40888	val_loss:	2.50764
epoch:	140	train_loss:	2.40895	val_loss:	2.50757
epoch:	145	train_loss:	2.40938	val_loss:	2.50767
epoch:	150	train_loss:	2.40904	val_loss:	2.50774
epoch:	155	train_loss:	2.40723	val_loss:	2.50768
epoch:	160	train_loss:	2.40589	val_loss:	2.50772
epoch:	165	train_loss:	2.40878	val_loss:	2.50769
epoch:	170	train_loss:	2.41019	val_loss:	2.50770
epoch:	175	train_loss:	2.40684	val_loss:	2.50770
epoch:	180	train_loss:	2.40928	val_loss:	2.50770
epoch:	185	train_loss:	2.40988	val_loss:	2.50770
epoch:	190	train_loss:	2.40901	val_loss:	2.50770
epoch:	195	train_loss:	2.40580	val_loss:	2.50770
epoch:	199	train_loss:	2.40833	val_loss:	2.50770
Final average normalized Wasserstein distance: 0.866772
Final average KL divergence: 0.375301
